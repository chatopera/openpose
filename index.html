<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>OpenPose: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenPose
   &#160;<span id="projectnumber">1.0.0rc2</span>
   </div>
   <div id="projectbrief">OpenPose: A Real-Time Multi-Person Key-Point Detection And Multi-Threading C++ Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">OpenPose Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><div align="center"> &lt;img src=".github/Logo_main_black.png", width="300"&gt; </div> <hr/>
<table class="doxtable">
<tr>
<th align="center"></th><th align="center"><code>Default Config</code> </th><th align="center"><code>CUDA (+Python)</code> </th><th align="center"><code>CPU (+Python)</code> </th><th align="center"><code>OpenCL (+Python)</code></th><th align="center"><code>Debug</code> </th><th align="center"><code>Unity</code>  </th></tr>
<tr>
<td align="center">**<code>Linux</code>** </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td><td align="center"><a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> </td></tr>
</table>
<p>| **<code>MacOS</code>** | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> | | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> | <a href="https://travis-ci.org/CMU-Perceptual-Computing-Lab/openpose"></a> |</p>
<p><a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose"><b>OpenPose</b></a> represents the <b>first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images</b>.</p>
<p>It is <b>authored by <a href="https://www.gineshidalgo.com">Gines Hidalgo</a>, <a href="https://people.eecs.berkeley.edu/~zhecao">Zhe Cao</a>, <a href="http://www.cs.cmu.edu/~tsimon">Tomas Simon</a>, <a href="https://scholar.google.com/citations?user=sFQD3k4AAAAJ&amp;hl=en">Shih-En Wei</a>, <a href="https://jhugestar.github.io">Hanbyul Joo</a>, and <a href="http://www.cs.cmu.edu/~yaser">Yaser Sheikh</a></b>. Currently, it is being <b>maintained by <a href="https://www.gineshidalgo.com">Gines Hidalgo</a> and <a href="https://www.raaj.tech">Yaadhav Raaj</a></b>. In addition, OpenPose would not be possible without the <a href="http://domedb.perception.cs.cmu.edu"><b>CMU Panoptic Studio dataset</b></a>. We would also like to thank all the people who helped OpenPose in any way. The main contributors are listed in doc/contributors.md.</p>
<p>&lt;img src="doc/media/pose_face_hands.gif", width="480"&gt; <br />
 <sup>Authors <a href="https://www.gineshidalgo.com" target="_blank">Gines Hidalgo</a> (left) and <a href="https://jhugestar.github.io" target="_blank">Hanbyul Joo</a> (right) in front of the <a href="http://domedb.perception.cs.cmu.edu" target="_blank">CMU Panoptic Studio</a></sup> </p>
<h2>Features</h2>
<ul>
<li><b>Functionality</b>:<ul>
<li><b>2D real-time multi-person keypoint detection</b>:<ul>
<li>15 or 18 or <b>25-keypoint body/foot keypoint estimation</b>. <b>Running time invariant to number of detected people</b>.</li>
<li><b>2x21-keypoint hand keypoint estimation</b>. Currently, <b>running time depends</b> on <b>number of detected people</b>.</li>
<li><b>70-keypoint face keypoint estimation</b>. Currently, <b>running time depends</b> on <b>number of detected people</b>.</li>
</ul>
</li>
<li><b>3D real-time single-person keypoint detection</b>:<ul>
<li>3-D triangulation from multiple single views.</li>
<li>Synchronization of Flir cameras handled.</li>
<li>Compatible with Flir/Point Grey cameras, but provided C++ demos to add your custom input.</li>
</ul>
</li>
<li><b>Calibration toolbox</b>:<ul>
<li>Easy estimation of distortion, intrinsic, and extrinsic camera parameters.</li>
</ul>
</li>
<li><b>Single-person tracking</b> for further speed up or visual smoothing.</li>
</ul>
</li>
<li><b>Input</b>: Image, video, webcam, Flir/Point Grey and IP camera. Included C++ demos to add your custom input.</li>
<li><b>Output</b>: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), and/or keypoints as array class.</li>
<li><b>OS</b>: Ubuntu (14, 16), Windows (8, 10), Mac OSX, Nvidia TX2.</li>
<li><b>Others</b>:<ul>
<li>Available: command-line demo, C++ wrapper, and C++ API.</li>
<li>**Python API**.</li>
<li><a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin"><b>Unity Plugin</b></a>.</li>
<li>CUDA (Nvidia GPU), OpenCL (AMD GPU), and CPU-only (no GPU) versions.</li>
<li>Training code included in the <a href="https://github.com/ZheC/Multi-Person-Pose-Estimation"><b>original CVPR 2017 GitHub repository</b></a>.</li>
</ul>
</li>
</ul>
<h2>Latest Features</h2>
<ul>
<li>Jan 2019: <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin"><b>Unity plugin released</b></a>!</li>
<li>Jan 2019: **Improved Python API** released! Including body, face, hands, and all the functionality of the C++ API!</li>
<li>Dec 2018: <a href="https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset"><b>Foot dataset</b></a> and <a href="https://arxiv.org/abs/1812.08008"><b>new paper released</b></a>!</li>
<li>Sep 2018: <a href="doc/quick_start.md#tracking"><b>Experimental single-person tracker</b></a> for further speed up or visual smoothing!</li>
<li>Jun 2018: **Combined body-foot model released! 40% faster and 5% more accurate**!</li>
<li>Jun 2018: **OpenCL/AMD graphic card version** released!</li>
<li>Jun 2018: **Calibration toolbox** released!</li>
</ul>
<p>For further details, check all released features and release notes.</p>
<h2>Results</h2>
<h3>Body and Foot Estimation</h3>
<p>&lt;img src="doc/media/dance_foot.gif", width="360"&gt; <br />
 <sup>Testing the <a href="https://www.youtube.com/watch?v=2DiQUX11YaY" target="_blank"><em>Crazy Uptown Funk flashmob in Sydney</em></a> video sequence with OpenPose</sup> </p>
<h3>3-D Reconstruction Module (Body, Foot, Face, and Hands)</h3>
<p>&lt;img src="doc/media/openpose3d.gif", width="360"&gt; <br />
 <sup>Testing the 3D Reconstruction Module of OpenPose</sup> </p>
<h3>Body, Foot, Face, and Hands Estimation</h3>
<p>&lt;img src="doc/media/pose_face.gif", width="360"&gt; &lt;img src="doc/media/pose_hands.gif", width="360"&gt; <br />
 <sup>Authors <a href="https://www.gineshidalgo.com" target="_blank">Gines Hidalgo</a> (left image) and <a href="http://www.cs.cmu.edu/~tsimon" target="_blank">Tomas Simon</a> (right image) testing OpenPose</sup> </p>
<h3>Unity Plugin</h3>
<p>&lt;img src="doc/media/unity_main.png", width="240"&gt; &lt;img src="doc/media/unity_body_foot.png", width="240"&gt; &lt;img src="doc/media/unity_hand_face.png", width="240"&gt; <br />
 <sup><a href="http://tianyizhao.com" target="_blank">Tianyi Zhao</a> and <a href="https://www.gineshidalgo.com" target="_blank">Gines Hidalgo</a> testing their <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin" target="_blank">OpenPose Unity Plugin</a></sup> </p>
<h3>Runtime Analysis</h3>
<p>Inference time comparison between the 3 available pose estimation libraries: OpenPose, Alpha-Pose (fast Pytorch version), and Mask R-CNN: </p>
<p>&lt;img src="doc/media/openpose_vs_competition.png", width="360"&gt; </p>
<p>This analysis was performed using the same images for each algorithm and a batch size of 1. Each analysis was repeated 1000 times and then averaged. This was all performed on a system with a Nvidia 1080 Ti and CUDA 8. Megvii (Face++) and MSRA GitHub repositories were excluded because they only provide pose estimation results given a cropped person. However, they suffer the same problem than Alpha-Pose and Mask R-CNN, their runtimes grow linearly with the number of people.</p>
<h2>Contents</h2>
<ol type="1">
<li><a href="#features">Features</a></li>
<li><a href="#latest-features">Latest Features</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#installation-reinstallation-and-uninstallation">Installation, Reinstallation and Uninstallation</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#output">Output</a></li>
<li><a href="#speeding-up-openpose-and-benchmark">Speeding Up OpenPose and Benchmark</a></li>
<li><a href="#foot-dataset">Foot Dataset</a></li>
<li><a href="#send-us-failure-cases-and-feedback">Send Us Failure Cases and Feedback!</a></li>
<li><a href="#citation">Citation</a></li>
<li><a href="#license">License</a></li>
</ol>
<h2>Installation, Reinstallation and Uninstallation</h2>
<p><b>Windows portable version</b>: Simply download and use the latest version from the <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose/releases">Releases</a> section.</p>
<p>Otherwise, check doc/installation.md for instructions on how to build OpenPose from source.</p>
<h2>Quick Start</h2>
<p>Most users do not need the OpenPose C++/Python API, but can simply use the OpenPose Demo:</p>
<ul>
<li><b>OpenPose Demo</b>: To easily process images/video/webcam and display/save the results. See doc/demo_overview.md. E.g., run OpenPose in a video with: <div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;# Ubuntu</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;./build/examples/openpose/openpose.bin --video examples/media/video.avi</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;:: Windows - Portable Demo</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;bin\OpenPoseDemo.exe --video examples\media\video.avi</div></div><!-- fragment --></li>
<li><b>Calibration toolbox</b>: To easily calibrate your cameras for 3-D OpenPose or any other stereo vision task. See doc/modules/calibration_module.md.</li>
<li><b>OpenPose C++ API</b>: If you want to read a specific input, and/or add your custom post-processing function, and/or implement your own display/saving, check the C++ API tutorial on <a href="examples/tutorial_api_cpp/">examples/tutorial_api_cpp/</a> and doc/library_introduction.md. You can create your custom code on <a href="examples/user_code/">examples/user_code/</a> and quickly compile it with CMake when compiling the whole OpenPose project. Quickly <b>add your custom code</b>: See examples/user_code/README.md for further details.</li>
<li><b>OpenPose Python API</b>: Analogously to the C++ API, find the tutorial for the Python API on <a href="examples/tutorial_api_python/">examples/tutorial_api_python/</a>.</li>
<li><b>Adding an extra module</b>: Check ./doc/library_add_new_module.md "doc/library_add_new_module.md".</li>
<li><b>Standalone face or hand detector</b>:<ul>
<li><b>Face</b> keypoint detection <b>without body</b> keypoint detection: If you want to speed it up (but also reduce amount of detected faces), check the OpenCV-face-detector approach in doc/standalone_face_or_hand_keypoint_detector.md.</li>
<li><b>Use your own face/hand detector</b>: You can use the hand and/or face keypoint detectors with your own face or hand detectors, rather than using the body detector. E.g., useful for camera views at which the hands are visible but not the body (OpenPose detector would fail). See doc/standalone_face_or_hand_keypoint_detector.md.</li>
</ul>
</li>
</ul>
<h2>Output</h2>
<p>Output (format, keypoint index ordering, etc.) in doc/output.md.</p>
<h2>Speeding Up OpenPose and Benchmark</h2>
<p>Check the OpenPose Benchmark as well as some hints to speed up and/or reduce the memory requirements for OpenPose on doc/speed_up_openpose.md.</p>
<h2>Foot Dataset</h2>
<p>Check the <a href="https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset/">foot dataset website</a> and new <a href="https://arxiv.org/abs/1812.08008">OpenPose paper</a> for more information.</p>
<h2>Send Us Failure Cases and Feedback!</h2>
<p>Our library is open source for research purposes, and we want to continuously improve it! So please, let us know if...</p>
<ol type="1">
<li>... you find videos or images where OpenPose does not seems to work well. Feel free to send them to <a href="#" onclick="location.href='mai'+'lto:'+'ope'+'np'+'ose'+'cm'+'u@g'+'ma'+'il.'+'co'+'m'; return false;">openp<span style="display: none;">.nosp@m.</span>osec<span style="display: none;">.nosp@m.</span>mu@gm<span style="display: none;">.nosp@m.</span>ail.<span style="display: none;">.nosp@m.</span>com</a> (email only for failure cases!), we will use them to improve the quality of the algorithm!</li>
<li>... you find any bug (in functionality or speed).</li>
<li>... you added some functionality to some class or some new Worker&lt;T&gt; subclass which we might potentially incorporate.</li>
<li>... you know how to speed up or improve any part of the library.</li>
<li>... you have a request about possible functionality.</li>
<li>... etc.</li>
</ol>
<p>Just comment on GitHub or make a pull request and we will answer as soon as possible! Send us an email if you use the library to make a cool demo or YouTube video!</p>
<h2>Citation</h2>
<p>Please cite these papers in your publications if it helps your research (the face keypoint detector was trained using the procedure described in [Simon et al. 2017] for hands): </p><pre class="fragment">@inproceedings{cao2018openpose,
  author = {Zhe Cao and Gines Hidalgo and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {arXiv preprint arXiv:1812.08008},
  title = {Open{P}ose: realtime multi-person 2{D} pose estimation using {P}art {A}ffinity {F}ields},
  year = {2018}
}

@inproceedings{cao2017realtime,
  author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},
  year = {2017}
}

@inproceedings{simon2017hand,
  author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},
  year = {2017}
}

@inproceedings{wei2016cpm,
  author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},
  booktitle = {CVPR},
  title = {Convolutional pose machines},
  year = {2016}
}
</pre><p>Links to the papers:</p>
<ul>
<li><a href="https://arxiv.org/abs/1812.08008">OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li>
<li><a href="https://arxiv.org/abs/1611.08050">Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li>
<li><a href="https://arxiv.org/abs/1704.07809">Hand Keypoint Detection in Single Images using Multiview Bootstrapping</a></li>
<li><a href="https://arxiv.org/abs/1602.00134">Convolutional Pose Machines</a></li>
</ul>
<h2>License</h2>
<p>OpenPose is freely available for free non-commercial use, and may be redistributed under these conditions. Please, see the [license](LICENSE) for further details. Interested in a commercial license? Check this <a href="https://flintbox.com/public/project/47343/">FlintBox link</a>. For commercial queries, use the <code>Directly Contact Organization</code> section from the <a href="https://flintbox.com/public/project/47343/">FlintBox link</a> and also send a copy of that message to <a href="http://www.cs.cmu.edu/~yaser/">Yaser Sheikh</a>. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
